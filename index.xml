<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ben&#39;s Data Science</title>
    <link>https://bdshaff.github.io/</link>
    <description>Recent content on Ben&#39;s Data Science</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 23 May 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://bdshaff.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Keras</title>
      <link>https://bdshaff.github.io/blog/2021-05-23-keras/</link>
      <pubDate>Sun, 23 May 2021 00:00:00 +0000</pubDate>
      
      <guid>https://bdshaff.github.io/blog/2021-05-23-keras/</guid>
      <description>library(tidyverse) library(tensorflow) library(keras) library(reticulate) use_condaenv(&amp;quot;~/miniforge3/envs/python38&amp;quot;) summary(model) ## Model: &amp;quot;sequential_2&amp;quot; ## ________________________________________________________________________________ ## Layer (type) Output Shape Param # ## ================================================================================ ## conv2d_8 (Conv2D) (None, 74, 74, 120) 1200 ## ________________________________________________________________________________ ## max_pooling2d_3 (MaxPooling2D) (None, 37, 37, 120) 0 ## ________________________________________________________________________________ ## conv2d_7 (Conv2D) (None, 18, 18, 60) 64860 ## ________________________________________________________________________________ ## conv2d_6 (Conv2D) (None, 8, 8, 60) 32460 ## ________________________________________________________________________________ ## max_pooling2d_2 (MaxPooling2D) (None, 4, 4, 60) 0 ## ________________________________________________________________________________ ## conv2d_5 (Conv2D) (None, 1, 1, 40) 21640 ## ________________________________________________________________________________ ## flatten_1 (Flatten) (None, 40) 0 ## ________________________________________________________________________________ ## dense_1 (Dense) (None, 2) 82 ## ================================================================================ ## Total params: 120,242 ## Trainable params: 120,242 ## Non-trainable params: 0 ## ________________________________________________________________________________ plotly::ggplotly( model_history %&amp;gt;% rownames_to_column(var = &amp;quot;batch&amp;quot;) %&amp;gt;% mutate(batch = as.</description>
    </item>
    
    <item>
      <title>First Steps with Neural Networks</title>
      <link>https://bdshaff.github.io/blog/2021-04-10-first-steps-with-neural-networks/</link>
      <pubDate>Sat, 10 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://bdshaff.github.io/blog/2021-04-10-first-steps-with-neural-networks/</guid>
      <description>import pandas as pd import numpy as np import matplotlib.pyplot as plt import keras from keras.layers import Dense, Conv2D, Flatten, BatchNormalization from keras.models import Sequential from keras.utils.np_utils import to_categorical y_train = pd.read_csv(&amp;quot;data/prepared/train/train_labels.csv&amp;quot;) X_train = pd.read_csv(&amp;quot;data/prepared/train/train_data_table.csv&amp;quot;) y_train = to_categorical(pd.Categorical(y_train.value).codes, num_classes=2) y_test = pd.read_csv(&amp;quot;data/prepared/test/test_labels.csv&amp;quot;) X_test = pd.read_csv(&amp;quot;data/prepared/test/test_data_table.csv&amp;quot;) y_test = to_categorical(pd.Categorical(y_test.value).codes, num_classes=2) X_train = np.array(X_train).reshape(13986, 150, 150, 1) X_test = np.array(X_test).reshape(2993, 150, 150, 1) model = Sequential() model.add(Conv2D(30, kernel_size=5, activation=&amp;#39;relu&amp;#39;, input_shape=(150, 150, 1), strides = 2)) model.</description>
    </item>
    
    <item>
      <title>Intro to Markov Chain Attribution</title>
      <link>https://bdshaff.github.io/blog/2021-04-02-markov-chain-attribution/</link>
      <pubDate>Fri, 02 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://bdshaff.github.io/blog/2021-04-02-markov-chain-attribution/</guid>
      <description>What is Attribution Modeling Attribution modeling is a task that comes up in Digital Marketing. Broadly speaking the objective of Attribution modeling is to improve the assessment of various Advertising Channels in driving Marketing Objectives. Before jumping to the data analysis let’s first set the context for the problem that Markov Chain Attribution modeling addresses.
With this post I am aiming to cover the following:</description>
    </item>
    
    <item>
      <title>Singular Value Decomposing 007&#39;s DB5</title>
      <link>https://bdshaff.github.io/blog/2021-04-02-singular-value-decomposing-007-s-db5/</link>
      <pubDate>Tue, 02 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://bdshaff.github.io/blog/2021-04-02-singular-value-decomposing-007-s-db5/</guid>
      <description>Singular Value Decomposition The SVD is one of the most useful matrix decomposition when it comes to Data Science. It’s used in practice for solving regression problems, various dimensionality reduction techniques including PCA, recommendation systems, image processing, and the list goes on.
My favorite thing about the SVD is that once you have the fundamentals of Linear Algebra down the SVD becomes pretty intuitive and easy to remember. I even coded it up myself with Rcpp - though admittedly my function is not as robust as what you will get with the out of the box functions in R or Python.</description>
    </item>
    
    <item>
      <title>QR Method to Compute Eigenvalues</title>
      <link>https://bdshaff.github.io/blog/2021-04-02-qr-method-to-compute-eigenvalues/</link>
      <pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://bdshaff.github.io/blog/2021-04-02-qr-method-to-compute-eigenvalues/</guid>
      <description>Eigenvalues In Linear Algebra and consequently in Data Science the concept of Eigenvalues is pretty important and useful to know given how often it comes up. You may encounter them when going over estimation of regression coefficients, unsupervised machine learning and dimensionality reduction, as well as all over mathematics and engineering. Outside of statistics I remember eigenvecotors being important in solving differential equations.</description>
    </item>
    
    <item>
      <title>About My Blog</title>
      <link>https://bdshaff.github.io/about/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://bdshaff.github.io/about/</guid>
      <description>About the blog: this is my space for publishing data science related thoughts. The posts will be about things that I learn, play with or revise. Sometimes I’ll share my thoughts about industry and career.
About me: I work in analytics in the advertising/media industry so the overarching function is to use data as a resource to generate insights and help clients make decisions. The spectrum of work is large ,ranging from developing software tools in R, working within database environments, doing adhoc and more formal data analysis, and of course tinkering with Microsoft Office tools.</description>
    </item>
    
  </channel>
</rss>
