<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog on Ben&#39;s Data Science</title>
    <link>https://bdshaff.github.io/blog/</link>
    <description>Recent content in Blog on Ben&#39;s Data Science</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sat, 10 Apr 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://bdshaff.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>First Steps with Neural Networks</title>
      <link>https://bdshaff.github.io/blog/2021-04-10-first-steps-with-neural-networks/</link>
      <pubDate>Sat, 10 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://bdshaff.github.io/blog/2021-04-10-first-steps-with-neural-networks/</guid>
      <description>import pandas as pd import numpy as np import matplotlib.pyplot as plt import keras from keras.layers import Dense, Conv2D, Flatten, BatchNormalization from keras.models import Sequential from keras.utils.np_utils import to_categorical y_train = pd.read_csv(&amp;quot;data/prepared/train/train_labels.csv&amp;quot;) X_train = pd.read_csv(&amp;quot;data/prepared/train/train_data_table.csv&amp;quot;) y_train = to_categorical(pd.Categorical(y_train.value).codes, num_classes=2) y_test = pd.read_csv(&amp;quot;data/prepared/test/test_labels.csv&amp;quot;) X_test = pd.read_csv(&amp;quot;data/prepared/test/test_data_table.csv&amp;quot;) y_test = to_categorical(pd.Categorical(y_test.value).codes, num_classes=2) X_train = np.array(X_train).reshape(13986, 150, 150, 1) X_test = np.array(X_test).reshape(2993, 150, 150, 1) model = Sequential() model.add(Conv2D(30, kernel_size=5, activation=&amp;#39;relu&amp;#39;, input_shape=(150, 150, 1), strides = 2)) model.</description>
    </item>
    
    <item>
      <title>Intro to Markov Chain Attribution</title>
      <link>https://bdshaff.github.io/blog/2021-04-02-markov-chain-attribution/</link>
      <pubDate>Fri, 02 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://bdshaff.github.io/blog/2021-04-02-markov-chain-attribution/</guid>
      <description>What is Attribution Modeling Attribution modeling is a task that comes up in Digital Marketing. Broadly speaking the objective of Attribution modeling is to improve the assessment of various Advertising Channels in driving Marketing Objectives. Before jumping to the data analysis let’s first set the context for the problem that Markov Chain Attribution modeling addresses.
With this post I am aiming to cover the following:</description>
    </item>
    
    <item>
      <title>Singular Value Decomposing 007&#39;s DB5</title>
      <link>https://bdshaff.github.io/blog/2021-04-02-singular-value-decomposing-007-s-db5/</link>
      <pubDate>Tue, 02 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://bdshaff.github.io/blog/2021-04-02-singular-value-decomposing-007-s-db5/</guid>
      <description>Singular Value Decomposition The SVD is one of the most useful matrix decomposition when it comes to Data Science. It’s used in practice for solving regression problems, various dimensionality reduction techniques including PCA, recommendation systems, image processing, and the list goes on.
My favorite thing about the SVD is that once you have the fundamentals of Linear Algebra down the SVD becomes pretty intuitive and easy to remember. I even coded it up myself with Rcpp - though admittedly my function is not as robust as what you will get with the out of the box functions in R or Python.</description>
    </item>
    
    <item>
      <title>QR Method to Compute Eigenvalues</title>
      <link>https://bdshaff.github.io/blog/2021-04-02-qr-method-to-compute-eigenvalues/</link>
      <pubDate>Tue, 02 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://bdshaff.github.io/blog/2021-04-02-qr-method-to-compute-eigenvalues/</guid>
      <description>Eigenvalues In Linear Algebra and consequently in Data Science the concept of Eigenvalues is pretty important and useful to know given how often it comes up. You may encounter them when going over estimation of regression coefficients, unsupervised machine learning and dimensionality reduction, as well as all over mathematics and engineering. Outside of statistics I remember eigenvecotors being important in solving differential equations.</description>
    </item>
    
  </channel>
</rss>
